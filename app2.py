import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import Chroma
from openai import OpenAI
from langchain.prompts import PromptTemplate
import base64, glob, os
from langchain_community.document_loaders import PyPDFLoader

st.set_page_config(page_title="AI Interior Style Analyzer", layout="centered")
st.title("ğŸ  ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ ë¶„ì„ & ë¬¸ì„œ ê¸°ë°˜ ì¶”ì²œ")

openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
client = OpenAI(api_key=openai_api_key) if openai_api_key else None
uploaded_image = st.file_uploader("ì¸í…Œë¦¬ì–´ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['png', 'jpg', 'jpeg'])

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "image_analysis" not in st.session_state:
    st.session_state["image_analysis"] = None
if "rag_result" not in st.session_state:
    st.session_state["rag_result"] = None

if uploaded_image:
    st.image(uploaded_image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", width=600)

    # ì¶”ê°€ ìš”êµ¬ì‚¬í•­ ì…ë ¥ë€
    user_req = st.text_input("ì¶”ê°€ ìš”êµ¬ì‚¬í•­(ì˜ˆ: ìì—°ì¹œí™”ì ì¸, ë‰´íŠ¸ëŸ´í†¤, ì†ŒíŒŒ ë“±)", "")

    if st.button("ìŠ¤íƒ€ì¼ ë¶„ì„ ë° ë¬¸ì„œ ê¸°ë°˜ ì¶”ì²œ"):
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ë° ë¬¸ì„œ ì°¸ì¡° ì¤‘..."):
                # 1. ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ë¶„ì„
                encoded = base64.b64encode(uploaded_image.getvalue()).decode("utf-8")
                styles = ["Modern", "Scandinavian", "Industrial", "Zen", "Minimalism", "Bohemian", "Brutalism", "Victorian"]
                prompt_text = (
                    "ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ê°€ì¥ ì í•©í•œ ìŠ¤íƒ€ì¼ì„ ê³ ë¥´ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n"
                    f"ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸: {', '.join(styles)}\n"
                    "ìƒ‰ìƒ, ê°€êµ¬ ë°°ì¹˜, ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ê°„ë‹¨í•œ í‰ê°€ë„ ì¶”ê°€í•´ì£¼ì„¸ìš”."
                )
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "You are an interior design expert."},
                        {"role": "user", "content": [
                            {"type": "text", "text": prompt_text},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded}"}}
                        ]}
                    ],
                    max_tokens=1000,
                    temperature=0.2,
                )
                image_analysis = response.choices[0].message.content

                # 2. PDF ë¬¸ì„œ RAG
                pdf_files = glob.glob("data/*.pdf")
                docs = []
                for pdf in pdf_files:
                    loader = PyPDFLoader(pdf)
                    pages = loader.load()
                    for p in pages:
                        p.metadata["source"] = pdf
                        p.metadata["page"] = p.metadata.get("page", 0)
                    docs.extend(pages)
                if not docs:
                    st.error("PDF ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
                texts = splitter.split_documents(docs)
                embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
                vectorstore = Chroma.from_documents(texts, embeddings, persist_directory="vectordb2")
                retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
                memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
                prompt = PromptTemplate(
                    template="""ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ë””ìì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\në¬¸ì„œ:\n{context}\n\nì§ˆë¬¸: {question}\n\nì°¸ì¡° ë¬¸ì„œë¥¼ ì¸ìš©í•˜ë©° ë‹µë³€í•˜ì„¸ìš”.\në‹µë³€:""",
                    input_variables=["context", "question"]
                )
                qa_chain = ConversationalRetrievalChain.from_llm(
                    llm=ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key),
                    retriever=retriever,
                    memory=memory,
                    combine_docs_chain_kwargs={"prompt": prompt}
                )
                rag_prompt = f"""
                ë‹¤ìŒì€ ì¸í…Œë¦¬ì–´ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{image_analysis}\n
                ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì°¸ì¡° ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ê´€ë ¨ëœ ì¸í…Œë¦¬ì–´ ë””ìì¸ ì›ì¹™ê³¼ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
                """
                rag_result = qa_chain({"question": rag_prompt})
                st.session_state["image_analysis"] = image_analysis
                st.session_state["rag_result"] = rag_result['answer']

    # ê²°ê³¼ê°€ ì„¸ì…˜ì— ì €ì¥ëì„ ë•Œë§Œ ë²„íŠ¼ í™œì„±í™”
    if st.session_state["rag_result"]:
        st.subheader("ğŸ” ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼")
        st.write(st.session_state["image_analysis"])

        st.subheader("ğŸ“š ë¬¸ì„œ ê¸°ë°˜ ì „ë¬¸ê°€ ì¶”ì²œ")
        st.write(st.session_state["rag_result"])

        if st.button("ë¦¬ëª¨ë¸ë§ ì´ë¯¸ì§€ ìƒì„± (DALLÂ·E)"):
            with st.spinner("DALLÂ·Eë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
                dalle_prompt = (
                    f"Photorealistic, clean, minimal, and realistic interior design for a living room. "
                    f"Do not overcrowd with furniture. Use only essential, modern, and stylish furniture. "
                    f"Natural lighting, balanced composition, and a sense of spaciousness. "
                    f"Reflect the following remodeling advice: {st.session_state['rag_result']}. "
                    f"User requirements: {user_req}. "
                    f"Make it look like a real, beautiful, and livable space."
                )
                img_response = client.images.generate(
                    model="dall-e-3",
                    prompt=dalle_prompt,
                    size="1024x1024",
                    n=1
                )
                img_url = img_response.data[0].url
                st.subheader("ğŸ–¼ï¸ ë¦¬ëª¨ë¸ë§ëœ ì¸í…Œë¦¬ì–´ ì´ë¯¸ì§€")
                st.image(img_url, caption="ë¦¬ëª¨ë¸ë§ ê²°ê³¼", use_column_width=True)
