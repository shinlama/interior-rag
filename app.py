import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import Chroma
from openai import OpenAI
import glob
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI Interior Advisor", layout="centered")
st.title("ğŸ  ì¸í…Œë¦¬ì–´ ë””ìì¸ í‰ê°€ ë° ë¦¬ëª¨ë¸ë§ ë°©ì•ˆ ì¶”ì²œ AI")

# OpenAI API í‚¤ ì…ë ¥
openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")

# GPT-4o API Client ì´ˆê¸°í™”
client = OpenAI(api_key=openai_api_key) if openai_api_key else None

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_image = st.file_uploader("ì¸í…Œë¦¬ì–´ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['png', 'jpg', 'jpeg'])

if uploaded_image:
    st.image(uploaded_image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_column_width=True)

    if st.button("ìŠ¤íƒ€ì¼ ë¶„ì„ ë° RAG ê¸°ë°˜ ë¦¬ëª¨ë¸ë§ ì¶”ì²œ"):
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ë° ë¬¸ì„œ ì°¸ì¡° ì¤‘ì…ë‹ˆë‹¤..."):
                
                # ì´ë¯¸ì§€ Base64 ì¸ì½”ë”©
                encoded_image = base64.b64encode(uploaded_image.getvalue()).decode('utf-8')

                # GPT-4o ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­
                styles = [
                    "Modern", "Contemporary", "Rustic", "Scandinavian", "Industrial",
                    "Hygge", "Sustainable", "Retro", "Zen", "Brutalism", "Mediterranean",
                    "Oriental", "Shabby", "Provence", "Cottage core", "Victorian",
                    "Tudor", "French", "Neo-classic", "Bohemian", "Art Nouveau",
                    "Maximalist", "Kinfolk", "Eclectic", "Junk"
                ]

                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ë””ìì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": [
                            {"type": "text", "text": f"""
                                ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ê°€ì¥ ì í•©í•œ ìŠ¤íƒ€ì¼ì„ ê³ ë¥´ê³  ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
                                ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸: {', '.join(styles)}
                                ë˜í•œ ìƒ‰ìƒ, ê°€êµ¬ ë°°ì¹˜, ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ê°„ë‹¨í•œ í‰ê°€ë„ ì¶”ê°€í•´ì£¼ì„¸ìš”. ê°€êµ¬ì— ìƒ‰ìƒì´ ìˆë‹¤ë©´ ì •í™•í•˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”.
                            """},
                            {"type": "image_url", "image_url": {
                                "url": f"data:image/jpeg;base64,{encoded_image}"
                            }}
                        ]}
                    ],
                    max_tokens=1000,
                    temperature=0.2,
                )

                image_analysis = response.choices[0].message.content

                st.subheader("ğŸ” ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼:")
                st.write(image_analysis)

                # RAG ë¬¸ì„œ ë¡œë”©
                pdf_files = glob.glob("data/*.pdf")
                all_docs = []
                for pdf_file in pdf_files:
                    loader = PyPDFLoader(pdf_file)
                    docs = loader.load()
                    all_docs.extend(docs)

                # í…ìŠ¤íŠ¸ ë¶„í•  ë° ë²¡í„°DB ìƒì„±
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
                texts = text_splitter.split_documents(all_docs)
                embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
                vectorstore = Chroma.from_documents(texts, embeddings, persist_directory="vectordb")

                # RAG Chain ìƒì„±
                memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
                qa_chain = ConversationalRetrievalChain.from_llm(
                    llm=ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key),
                    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
                    memory=memory
                )

                # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RAG í‰ê°€ ë° ì¶”ì²œ
                rag_prompt = f"""
                ë‹¤ìŒì€ í•œ ì¸í…Œë¦¬ì–´ ì´ë¯¸ì§€ì— ëŒ€í•œ GPT-4oì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:
                {image_analysis}

                ìœ„ ë¶„ì„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¸í…Œë¦¬ì–´ ì „ë¬¸ê°€ì˜ ê´€ì ì—ì„œ ë”ìš± ìƒì„¸í•˜ê²Œ í‰ê°€í•˜ê³ , ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•´ ì£¼ì„¸ìš”. 
                íŠ¹íˆ ì¸í…Œë¦¬ì–´ ë¬¸ì„œì—ì„œ ì°¸ì¡°í•œ ì „ë¬¸ê°€ì  ì˜ê²¬ì´ë‚˜ ìŠ¤íƒ€ì¼, ê°€êµ¬ ë°°ì¹˜, ìƒ‰ìƒì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
                """

                rag_result = qa_chain({"question": rag_prompt})
                st.subheader("ğŸ“š ì „ë¬¸ê°€ ë¬¸ì„œ ì°¸ì¡° í‰ê°€ ë° ì¶”ì²œ:")
                st.write(rag_result['answer'])

                # ìƒì„¸í•œ ë¦¬ëª¨ë¸ë§ ë°©ì•ˆ ì¶”ê°€ ìš”ì²­
                remodel_prompt = f"""
                ìœ„ì˜ ì „ë¬¸ê°€ í‰ê°€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ ê³µê°„ì˜ ë¦¬ëª¨ë¸ë§ ë°©ì•ˆì„ ë”ìš± êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                ì¶”ì²œí•˜ëŠ” ì¸í…Œë¦¬ì–´ ì†Œí’ˆ ì¶”ì²œì´ë‚˜ ê°€êµ¬ ë°°ì¹˜ ë°©ë²•, ìƒ‰ìƒ ì¡°í•© ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”.
                """

                remodel_result = qa_chain({"question": remodel_prompt})
                st.subheader("âœ¨ êµ¬ì²´ì ì¸ ë¦¬ëª¨ë¸ë§ ë°©ì•ˆ ì¶”ì²œ:")
                st.write(remodel_result['answer'])
