import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import Chroma
from openai import OpenAI
import glob
import base64
from langchain.prompts import PromptTemplate

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI Interior Advisor", layout="centered")
st.title("ğŸ  ì¸í…Œë¦¬ì–´ ë””ìì¸ í‰ê°€ ë° ë¦¬ëª¨ë¸ë§ ë°©ì•ˆ ì¶”ì²œ AI")

# OpenAI API í‚¤ ì…ë ¥
openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")

# GPT-4o API Client ì´ˆê¸°í™”
client = OpenAI(api_key=openai_api_key) if openai_api_key else None

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_image = st.file_uploader("ì¸í…Œë¦¬ì–´ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['png', 'jpg', 'jpeg'])

if uploaded_image:
    st.image(uploaded_image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_container_width=True)

    if st.button("ìŠ¤íƒ€ì¼ ë¶„ì„ ë° RAG ê¸°ë°˜ ë¦¬ëª¨ë¸ë§ ì¶”ì²œ"):
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ë° ë¬¸ì„œ ì°¸ì¡° ì¤‘ì…ë‹ˆë‹¤..."):
                
                # ì´ë¯¸ì§€ Base64 ì¸ì½”ë”©
                encoded_image = base64.b64encode(uploaded_image.getvalue()).decode('utf-8')

                # GPT-4o ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­
                styles = [
                    "Modern", "Contemporary", "Rustic", "Scandinavian", "Industrial",
                    "Hygge", "Sustainable", "Retro", "Zen", "Brutalism", "Mediterranean",
                    "Oriental", "Shabby", "Provence", "Cottage core", "Victorian",
                    "Tudor", "French", "Neo-classic", "Bohemian", "Art Nouveau",
                    "Maximalist", "Kinfolk", "Eclectic", "Junk"
                ]

                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ë””ìì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": [
                            {"type": "text", "text": f"""
                                ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ê°€ì¥ ì í•©í•œ ìŠ¤íƒ€ì¼ì„ ê³ ë¥´ê³  ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
                                ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸: {', '.join(styles)}
                                ë˜í•œ ìƒ‰ìƒ, ê°€êµ¬ ë°°ì¹˜, ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ê°„ë‹¨í•œ í‰ê°€ë„ ì¶”ê°€í•´ì£¼ì„¸ìš”. ê°€êµ¬ì— ìƒ‰ìƒì´ ìˆë‹¤ë©´ ì •í™•í•˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”.
                            """},
                            {"type": "image_url", "image_url": {
                                "url": f"data:image/jpeg;base64,{encoded_image}"
                            }}
                        ]}
                    ],
                    max_tokens=1000,
                    temperature=0.2,
                )

                image_analysis = response.choices[0].message.content

                st.subheader("ğŸ” ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼:")
                st.write(image_analysis)

                # RAG ë¬¸ì„œ ë¡œë”© ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
                pdf_files = glob.glob("data/*.pdf")
                all_docs = []

                st.write(f"ì°¾ì€ PDF íŒŒì¼ë“¤: {pdf_files}")  # ë””ë²„ê¹…ìš©

                for pdf_file in pdf_files:
                    try:
                        loader = PyPDFLoader(pdf_file)
                        pages = loader.load()
                        st.write(f"{pdf_file}ì—ì„œ {len(pages)}í˜ì´ì§€ ë¡œë“œë¨")  # ë””ë²„ê¹…ìš©
                        # ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„° ëª…í™•íˆ ì¶”ê°€
                        for doc in pages:
                            doc.metadata['source'] = pdf_file
                            doc.metadata['page'] = doc.metadata.get('page', 0)
                        all_docs.extend(pages)
                    except Exception as e:
                        st.error(f"PDF ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

                if not all_docs:
                    st.error("PDF ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                # í…ìŠ¤íŠ¸ ë¶„í•  (ìµœì  split ì „ëµ ìœ ì§€)
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000,
                    chunk_overlap=150,
                    length_function=len,
                    separators=["\n\n", "\n", " ", ""]
                )
                texts = text_splitter.split_documents(all_docs)
                st.write(f"ì´ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„±ë¨")  # ë””ë²„ê¹…ìš©

                # OpenAI Embeddingsë¡œ ë²¡í„°DB ìƒì„± (Chroma ìœ ì§€)
                embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
                vectorstore = Chroma.from_documents(documents=texts, embedding=embeddings, persist_directory="vectordb")

                # ì‹ ë¢°ì„± ë†’ì€ ì¶œì²˜ ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ìƒì„±
                retriever = vectorstore.as_retriever(
                    search_kwargs={"k": 4}
                )

                # ë©”ëª¨ë¦¬ ë° RAG ì²´ì¸ ìœ ì§€
                memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

                qa_chain = ConversationalRetrievalChain.from_llm(
                    llm=ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key),
                    retriever=retriever,
                    memory=memory,
                    combine_docs_chain_kwargs={"prompt": PromptTemplate(
                        template="""ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ë””ìì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

                        ì°¸ì¡° ë¬¸ì„œ:
                        {context}

                        ì§ˆë¬¸: {question}

                        ë‹µë³€í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì°¸ì¡° ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¸ìš©í•˜ê³ , í•´ë‹¹ ë‚´ìš©ì´ ì–´ë–¤ ë¬¸ì„œì—ì„œ ì™”ëŠ”ì§€ ëª…ì‹œí•´ì£¼ì„¸ìš”.
                        ë‹µë³€:""",
                        input_variables=["context", "question"]
                    )}
                )

                # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ RAG í‰ê°€ ë° ì¶”ì²œ
                rag_prompt = f"""
                ë‹¤ìŒì€ ì¸í…Œë¦¬ì–´ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:
                {image_analysis}

                ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì°¸ì¡° ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ê´€ë ¨ëœ ì¸í…Œë¦¬ì–´ ë””ìì¸ ì›ì¹™ê³¼ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
                íŠ¹íˆ ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
                1. í˜„ì¬ ê³µê°„ì˜ ìŠ¤íƒ€ì¼ê³¼ ê´€ë ¨ëœ ì „ë¬¸ê°€ì˜ ì¡°ì–¸
                2. ìƒ‰ìƒ, ê°€êµ¬ ë°°ì¹˜, ì¡°ëª… ë“±ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ
                3. ì°¸ì¡° ë¬¸ì„œì—ì„œ ì¸ìš©í•œ ë‚´ìš©ê³¼ í•´ë‹¹ ë¬¸ì„œì˜ ì¶œì²˜
                """

                rag_result = qa_chain({"question": rag_prompt})
                
                st.subheader("ğŸ“š ì „ë¬¸ê°€ ë¬¸ì„œ ì°¸ì¡° í‰ê°€ ë° ì¶”ì²œ:")
                st.write(rag_result['answer'])

                # ì†ŒìŠ¤ ë¬¸ì„œ ì¶œì²˜ ëª…í™•íˆ í‘œì‹œ
                if 'source_documents' in rag_result:
                    st.subheader("ğŸ“‘ ì°¸ì¡°í•œ ë¬¸ì„œ ì¶œì²˜:")
                    for doc in rag_result['source_documents']:
                        source = doc.metadata.get('source', 'Unknown')
                        page = doc.metadata.get('page', 'Unknown')
                        st.write(f"ğŸ“„ **íŒŒì¼ëª…**: {source}, ğŸ“ƒ **í˜ì´ì§€**: {page}")
